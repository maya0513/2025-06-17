# ./発表スライド.md に書かれている実験装置の実装を行います。

- 実機は HTC VIVE 系（VIVE Focus Vision + VIVE Tracker）を使用します。

---

Unity で実行する AR アプリケーションを開発し、VIVE トラッカー群から取得するモーションデータをリアルタイムに処理して（1）視覚／聴覚フィードバックを AR パススルー越しに提示、（2）生データを CSV で記録、（3）実験のセッション管理とログ出力を行う。ヘッドセットは AR（現実描画）のままオーバーレイ表示）でフィードバックを出すことを必須要件とする。VIVE OpenXR を利用する。

---

## ハードウェア

- ヘッドセット: VIVE Focus Vision
- トラッカー: VIVE Trackers 4 台使用（左手首／右手首／左車輪／右車輪）。VIVE OpenXR プラグインでトラッカー位置・姿勢を取得。
- ヘッドセット内蔵スピーカー（左右）で聴覚フィードバック出力。
- 開発環境: Unity 6

---

1. unity アプリケーションを起動すると新規の被験者か ID 割り当て済みの被験者かを尋ねる。

- 新規の被験者の場合: まず被験者 ID を割り当てる、ID は 1 から順に小さな値を与える。次に、/視覚/聴覚/フィードバックなしのどの群かを選択させる。その後、実験フェーズ選択画面に移行
- ID 割り当て済みの被験者の場合: 実験フェーズ選択画面に移行

2. 実験フェーズ選択画面

- 事前テスト/トレーニング/事後テスト/保持テストの中から選択
- 選択後、ジグザグ走/8 の字走/バスケットボールを持ちながらの 8 の字走の中から選択
- タスクの種類を選択後、スタート

3. フィードバック

- 視覚フィードバック: 画面上の左右に 2 本のバーを表示する。左右のバーそれぞれが車いすの両輪に取り付けられたトラッカーの動きに対応している。

とりあえず選択画面と視覚フィードバックのバーを実装してください。それ以外は後ほど実装します。見た目だけ作ってください。また、私が行うべき unity 側での設定も書いてください。数学的な処理はあとで実装しますのでハリボテでいいです。
